<!DOCTYPE html>
<html lang="en">
<head>
<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-X3HG4WG8DR"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-X3HG4WG8DR');
</script>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>J's Blog</title>
</head>
<body>
  <header>
    <h1>J's Blog</h1>
  </header>
  <nav>
    <a href="index.html">Home</a>
    <a href="blog.html">Posts</a>
  </nav>
  <main> 
    <article>  
      <h2> 1.1: A small collection of previous bangers </h2> 
      <p> (To audience of Stanford students) Ok this should be common sense but y'all should actually enjoy your major. I'm a bit obsessive (like I read math papers/write transformers from scratch on saturdays) but if u wanna die every day don't do it.
      </p>  
      <p>  
       This is your life and don't waste it on stuff that you don't even like. The privilege of a place like Stanford is that you can do (almost) anything. Your limit is your imagination and howeve rmuch money you can steal from VCs. 
      </p> 
      <p>
       You'll make way more money if you like what you do (at least a little bit) than if you completely hate your job. Why? Exceptional talent is rewarded. A child who's main talent is doing unboxing videos makes more than most CEOs. There are multiple professional whistlers. If you're good you're good.
      </p> 
      <p>  
       Now going for passion as your sole determinant for "this is what I want to do with my life" is flawed (re. The Trouble With Passion (Cich)) but if you have the choice do something you don't absolutely despise. You'll have plenty of time for that when tax season comes around. (unless if you like doing taxes. If that is the case my email is jrin@stanford.edu)
      </p>
    <article>
    <article>
      <h2> 1: Robots that don't suck </h2>
      <p> Hey everyone, this is my first post on my new little website. 
        I need to still add in stripe stuff and make it not look awful but let’s get down to something I’ve been obsessed with the past few days:
      </p>
      <p>
      LLMs are going to make robots not suck for once.  
      </p>
      <p>
      Explain? 
      </p>
      <p>
      Robots currently suck. There’s lots of reasons for this, but a big one is that we don’t speak the same language. 
      Humans deal with messy, vague, intuitive language, while robots deal with precise, exact code. 
      </p>
      <p>
      A computer will do exactly what you tell it to do. 
      </p>
      <p>
      No more.
      </p>
      <p> 
      No less.
      </p>
      <p> 
      So then, how do we fix this problem? 
      </p>
      <p> 
      For the longest time, we didn’t. People slapped a bunch of sensors onto stuff and tried some primitive CV models, but they weren’t sci-fi level. 
      </p>
      <p>
      Now we get to the good part: ChatGPT and GPT-4. Both of these LLMs blew away previously available consumer LLMs, and have rapidly been integrated into a bunch of different robots. 
      While embodied models such as PaLM-E also are leading in the space, nobody outside of Google Research can actually use it, so ordinary people (like me) are going to have to work with OpenAI for now.  
      </p>
      <p> 
      Now, the big workflow for how to actually use LLMs for robots is that they essentially just move you up a level of abstraction. 
      Instead of telling the robot through code directly what to do, you tell the LLM to tell the robot through code to do what you want it to do. 
      I haven’t seen anyone try testing code-specific LLMs on these sorts of tasks yet, but I wonder if they would end up being more efficient for this type of work. 
      </p> 
      <p> 
      However, while this is nice, the most immediate commercial use cases for LLMs in robotics will likely be as a nice UI for databases/robot information. 
      Boston Dynamics was good with this for integrating ChatGPT into their SPOT dog robot and asking it questions such as 
      “what is your battery percentage?” 
      “How many thermal anomalies did you find 30 minutes ago?” 
      “Is that menswear guy on twitter near my house again please sir stop I’m scared” etc. 
      </p> 
      <p>
      Some interesting directions beyond these two are that Microsoft Research used LLMs for drones (my friend brian also did this for treehacks, although not at the same scale due to hackathon limitations) and the University of Florida did a study where 15 people tried interacting with a robot through LLMs. (Spoiler alert: It’s actually really good and will probably get deployed in factories once guardrails have been deployed). 
      </p> 
      <p>
      Oh yeah. Guardrails. 
      </p> 
      <p>
      See, there’s problems with just blindly slapping LLMs into robots. 
      It’s fun when it’s a party trick or helping factories become more efficient, but not when it gets integrated into police or military units. Hallucination is bad but to me prompt injection seems significantly more pressing. Do Anything Now (DAN) and other techniques could cause quite a bit of harm if they aren’t accounted for. Currently I don’t know of any good solutions besides mass RLHF and a very dedicated team of engineers, but if there’s any politicians (or other persons)  in NYC that read this blog you should seriously consider this before it gets messy. 
      </p> 
      <p>
      Anyways I have things (homework and laundry) to attend to, but this was nice. 
      </p> 
      <p>
      Go outside and enjoy the weather. 
      </p> 
      <p>
      -J
      </p>
    </article>
  </main>
  <footer>
    <p>&copy; J </p>
  </footer>
</body>
</html>
